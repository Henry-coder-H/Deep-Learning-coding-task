import cv2
import torch
import numpy as np
import sys
import os
import time
import psutil  # <--- æ–°å¢åº“ï¼šç”¨äºè·å–å†…å­˜å ç”¨
from collections import Counter, defaultdict
from ultralytics import YOLO

# ================= 1. é…ç½®åŒºåŸŸ =================
VIDEO_PATH = 'test_video.mp4'
YOLO_WEIGHTS = 'weights/license_plate_detector.pt'
# LPR_WEIGHTS = 'LPRNet_Pytorch/weights/Final_LPRNet_model.pth'
LPR_WEIGHTS = 'weights/lprnet_best.pth'

# ã€çœŸå€¼ç™½åå•ã€‘ (å¡«å…¥è§†é¢‘é‡Œæ‰€æœ‰æ­£ç¡®çš„è½¦ç‰Œ)
TRUE_PLATES = [
    "äº¬GPL768",
    "äº¬BF1144",
    "äº¬M76967",
    "äº¬B06498",
    "äº¬L87802",
    "äº¬J27373",
    "äº¬KS0537",
    "äº¬JZ9445",
    # ... ç»§ç»­æ·»åŠ 
]

# ================= 2. æ ¸å¿ƒé€»è¾‘ =================
current_dir = os.path.dirname(os.path.abspath(__file__))
lprnet_path = os.path.join(current_dir, 'LPRNet_Pytorch')
if lprnet_path not in sys.path:
    sys.path.append(lprnet_path)
from model.LPRNet import LPRNet

# CHARS = ['äº¬', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 
#          'è‹', 'æµ™', 'çš–', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 
#          'æ¡‚', 'ç¼', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', 'é’', 'å®', 
#          'æ–°', 
#          '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 
#          'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 
#          'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 
#          'W', 'X', 'Y', 'Z', 'I', 'O', '-'
# ]

# LPRNet è®­ç»ƒéœ€è¦çš„å…¨å±€å­—ç¬¦è¡¨ï¼ˆå»é‡å¹¶æ’åºï¼Œä¿æŒ 'O' ä½œä¸ºç©ºç™½ç¬¦åœ¨æœ€åæˆ–è€…æ˜¯ç‰¹å®šçš„ä½ç½®ï¼‰
# è¿™é‡Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯èƒ½å­—ç¬¦çš„åˆ—è¡¨
CHARS = ['çš–', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'è‹',
          'æµ™', 'äº¬', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼',
            'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', "é’", "å®", "æ–°", "è­¦", "å­¦", 
         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N',
           'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 
         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] # æœ€ååŠ ä¸ª '-' ä½œä¸ºç©ºç™½ç¬¦(blank)

class VideoEvaluator:
    def __init__(self):
        self.fps_history = []
        self.predictions = defaultdict(list)
        
    def add_record(self, track_id, text, inference_ms, frame_idx):
        self.predictions[track_id].append((frame_idx, text))
        self.fps_history.append(inference_ms)

    def calculate_max_consecutive(self, frame_indices):
        """è®¡ç®—æœ€å¤§è¿ç»­å¸§æ•°"""
        if not frame_indices: return 0
        sorted_frames = sorted(frame_indices)
        max_cons = 1
        current_cons = 1
        for i in range(1, len(sorted_frames)):
            if sorted_frames[i] == sorted_frames[i-1] + 1:
                current_cons += 1
            else:
                max_cons = max(max_cons, current_cons)
                current_cons = 1
        return max(max_cons, current_cons)

    def print_report(self, vram_peak, ram_usage):
        print("\n" + "="*95)
        print("ğŸ¬ è§†é¢‘å¤„ç†æ€§èƒ½è¯„ä¼°æŠ¥å‘Š (åŒ…å«æ˜¾å­˜/å†…å­˜ç»Ÿè®¡)")
        print("="*95)
        
        avg_ms = np.mean(self.fps_history) if self.fps_history else 0
        fps = 1000.0 / avg_ms if avg_ms > 0 else 0
        
        # 1. é€Ÿåº¦æŒ‡æ ‡
        print(f"â±ï¸  å¹³å‡é€Ÿåº¦ (Latency):")
        print(f"    - FPS: {fps:.2f}")
        print(f"    - å•å¸§è€—æ—¶: {avg_ms:.2f} ms")
        print("-" * 95)
        
        # 2. è¯†åˆ«è¯¦æƒ…
        print(f"{'ID':<4} | {'è¯†åˆ«ç»“æœ (Result)':<12} | {'å¸§æ•°':<4} | {'æœ€å¤§è¿ç»­':<8} | {'å æ¯”':<6} | {'åˆ¤å®š'}")
        print("-" * 95)
        
        found_true_plates = set()
        total_frames_processed = 0
        total_correct_frames = 0
        
        for tid, data_list in sorted(self.predictions.items()):
            all_texts = [x[1] for x in data_list]
            all_indices = [x[0] for x in data_list]
            
            counter = Counter(all_texts)
            sorted_results = counter.most_common()
            
            total_id_frames = len(all_texts)
            total_frames_processed += total_id_frames
            
            first_row = True
            for text, count in sorted_results:
                current_indices = [idx for idx, t in zip(all_indices, all_texts) if t == text]
                max_cons = self.calculate_max_consecutive(current_indices)
                ratio = (count / total_id_frames) * 100
                
                if text in TRUE_PLATES:
                    status = "âœ… æ­£ç¡®"
                    found_true_plates.add(text)
                    total_correct_frames += count
                else:
                    status = "âŒ æœªçŸ¥"
                
                id_str = str(tid) if first_row else ""
                print(f"{id_str:<4} | {text:<12} | {count:<4} | {max_cons:<8} | {ratio:.1f}%  | {status}")
                first_row = False
            
            print("-" * 95)

        # 3. ç»Ÿè®¡æ‘˜è¦
        recall = (len(found_true_plates) / len(TRUE_PLATES)) * 100 if TRUE_PLATES else 0
        frame_acc = (total_correct_frames / total_frames_processed) * 100 if total_frames_processed else 0
        
        print(f"ğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
        print(f"   1. å¬å›ç‡ (Recall):   {recall:.2f}%  (ç™½åå•é‡Œçš„ {len(TRUE_PLATES)} è¾†è½¦ï¼Œæ‰¾åˆ°äº† {len(found_true_plates)} è¾†)")
        print(f"   2. å¸§å‡†ç¡®ç‡ (Frame Acc): {frame_acc:.2f}% (æ‰€æœ‰å¤„ç†å¸§ä¸­ï¼Œæœ‰ {total_correct_frames} å¸§æ˜¯å®Œå…¨æ­£ç¡®çš„)")
        print("-" * 95)

        # 4. æ˜¾å­˜/å†…å­˜å ç”¨ (æ–°å¢æ¿å—)
        print(f"ğŸ’¾ èµ„æºå ç”¨ (Memory Usage):")
        print(f"   - GPU æ˜¾å­˜å³°å€¼ (VRAM Peak): {vram_peak:.2f} MB  (è¶Šå°è¶Šå¥½ï¼Œé˜²æ­¢ OOM)")
        print(f"   - CPU å†…å­˜å ç”¨ (RAM Usage): {ram_usage:.2f} MB")
        print("="*95)

def load_lprnet(weights_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    lprnet = LPRNet(lpr_max_len=8, phase=False, class_num=len(CHARS), dropout_rate=0)
    lprnet.to(device)
    lprnet.load_state_dict(torch.load(weights_path, map_location=device))
    lprnet.eval()
    return lprnet, device

def decode_lpr(preds):
    preds = preds.cpu().detach().numpy()
    label_indices = np.argmax(preds, axis=1)
    decoded_str = ""
    last_char = -1
    for idx in label_indices[0]:
        if idx != last_char and idx != len(CHARS) - 1:
            decoded_str += CHARS[idx]
        last_char = idx
    return decoded_str

def preprocess_plate(img, device):
    img = cv2.resize(img, (94, 24))
    img = img.astype('float32')
    img -= 127.5
    img *= 0.0078125
    img = np.transpose(img, (2, 0, 1))
    img = torch.from_numpy(img).unsqueeze(0).to(device)
    return img

def main():
    # --- ğŸ” ç¡¬ä»¶è‡ªæ£€ ---
    print(f"ğŸ–¥ï¸  æ­£åœ¨æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒ...")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        # é‡ç½®æ˜¾å­˜ç»Ÿè®¡ï¼Œç¡®ä¿ä»å½“å‰è„šæœ¬å¼€å§‹è®¡ç®—
        torch.cuda.reset_peak_memory_stats()
        print(f"âœ… æˆåŠŸè°ƒç”¨ GPU: {gpu_name}")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ° GPUï¼Œæ­£åœ¨ä½¿ç”¨ CPU è·‘ä»£ç ")
    # ---------------------
    
    yolo = YOLO(YOLO_WEIGHTS)
    lpr, device = load_lprnet(LPR_WEIGHTS)
    evaluator = VideoEvaluator()
    cap = cv2.VideoCapture(VIDEO_PATH)
    cv2.namedWindow('Member 3 - Visualization', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('Member 3 - Visualization', 1024, 768)

    print("ğŸ¥ å¼€å§‹è¿è¡Œ (V6 - å«å†…å­˜ç»Ÿè®¡)...")
    frame_idx = 0
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        frame_idx += 1
        t0 = time.time()
        
        # è¿½è¸ª
        results = yolo.track(frame, persist=True, verbose=False, imgsz=320)
        
        for result in results:
            if result.boxes is None or result.boxes.id is None: continue
            boxes = result.boxes.xyxy.cpu().numpy()
            ids = result.boxes.id.cpu().numpy().astype(int)
            
            for box, track_id in zip(boxes, ids):
                x1, y1, x2, y2 = map(int, box)
                if (x2-x1) < 30: continue
                
                # è£å‰ª
                h, w = frame.shape[:2]
                crop = frame[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]
                if crop.size == 0: continue
                
                # è¯†åˆ«
                inp = preprocess_plate(crop, device)
                with torch.no_grad():
                    text = decode_lpr(lpr(inp))
                
                t_cost = (time.time() - t0) * 1000
                evaluator.add_record(track_id, text, t_cost, frame_idx)
                
                # å¯è§†åŒ–
                if text in TRUE_PLATES:
                    color = (0, 255, 0)
                    status_text = "MATCH"
                else:
                    color = (0, 0, 255)
                    status_text = "UNKNOWN"
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                # (ç»˜å›¾éƒ¨åˆ†ç®€åŒ–ä»¥ä¿æŒæµç•…)

        cv2.imshow('Member 3 - Visualization', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
            
    cap.release()
    cv2.destroyAllWindows()
    
    # --- ğŸ“Š é‡‡é›†æœ€ç»ˆå†…å­˜æ•°æ® ---
    vram_peak_mb = 0
    if torch.cuda.is_available():
        # è·å–æœ€å¤§æ˜¾å­˜å ç”¨ (Max Memory Allocated)
        vram_peak_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)
    
    # è·å–å½“å‰è¿›ç¨‹çš„ RAM å ç”¨
    process = psutil.Process(os.getpid())
    ram_usage_mb = process.memory_info().rss / (1024 ** 2)
    
    # æ‰“å°æŠ¥è¡¨
    evaluator.print_report(vram_peak_mb, ram_usage_mb)

if __name__ == "__main__":
    main()