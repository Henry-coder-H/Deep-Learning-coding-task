import sys
import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import Dataset, DataLoader
from imutils import paths
import cv2
import os

# ==========================================
# 1. å®šä¹‰å­—ç¬¦æ˜ å°„è¡¨ (æ ¹æ®ä½ æä¾›çš„ä¿¡æ¯)
# ==========================================
PROVINCES = ["çš–", "æ²ª", "æ´¥", "æ¸", "å†€", "æ™‹", "è’™", "è¾½", "å‰", "é»‘", "è‹", "æµ™", "äº¬", "é—½", "èµ£", "é²", "è±«", "é„‚", "æ¹˜", "ç²¤", "æ¡‚", "ç¼", "å·", "è´µ", "äº‘", "è—", "é™•", "ç”˜", "é’", "å®", "æ–°", "è­¦", "å­¦", "O"]
ALPHABETS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']
ADS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']

# LPRNet è®­ç»ƒéœ€è¦çš„å…¨å±€å­—ç¬¦è¡¨ï¼ˆå»é‡å¹¶æ’åºï¼Œä¿æŒ 'O' ä½œä¸ºç©ºç™½ç¬¦åœ¨æœ€åæˆ–è€…æ˜¯ç‰¹å®šçš„ä½ç½®ï¼‰
# è¿™é‡Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯èƒ½å­—ç¬¦çš„åˆ—è¡¨
CHARS = ['çš–', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'è‹', 'æµ™', 'äº¬', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', "é’", "å®", "æ–°", "è­¦", "å­¦", 
         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 
         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] # æœ€ååŠ ä¸ª '-' ä½œä¸ºç©ºç™½ç¬¦(blank)

# åˆ›å»ºå­—ç¬¦åˆ°ç´¢å¼•çš„å­—å…¸ï¼Œæ–¹ä¾¿è½¬æ¢
CHAR_DICT = {char: i for i, char in enumerate(CHARS)}

# ==========================================
# 2. è‡ªå®šä¹‰ CCPD æ•°æ®é›†è¯»å–ç±»
# ==========================================
class CCPDDataset(Dataset):
    def __init__(self, img_paths, img_size=(94, 24), transform=None):
        self.img_paths = img_paths
        self.img_size = img_size
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, index):
        filename = self.img_paths[index]
        image = cv2.imread(filename)
        
        # å¼‚å¸¸å¤„ç†ï¼šå¦‚æœè¯»å›¾å¤±è´¥
        if image is None:
            return self.__getitem__(np.random.randint(self.__len__()))

        h, w, _ = image.shape
        
        # --- è§£ææ–‡ä»¶å ---
        # ç¤ºä¾‹: 025-95_113-154,383_386,473-386,473_177,454_154,383_363,402-0_0_22_27_27_33_16-37-15.jpg
        try:
            basename = os.path.basename(filename)
            split_name = basename.split('-')
            
            # 1. è·å–è¾¹ç•Œæ¡† (Bounding Box) - å¯¹åº”ç´¢å¼• 2
            # æ ¼å¼: 154&383_386&473 (LeftUp_RightBottom) -> x1&y1_x2&y2
            # --- ä¿®æ­£å¼€å§‹ ---
            coords = split_name[2].split('_')
            
            # 1. å…ˆæŠŠå¯èƒ½å‡ºç°çš„é€—å·æ›¿æ¢æˆ '&'
            # 2. ç„¶åå† splitï¼Œè¿™æ ·æ— è®ºæ•°æ®æ˜¯ "100&200" è¿˜æ˜¯ "100,200" éƒ½èƒ½è·‘
            txt_point1 = coords[0].replace(',', '&')
            txt_point2 = coords[1].replace(',', '&')
            
            x1, y1 = map(int, txt_point1.split('&'))
            x2, y2 = map(int, txt_point2.split('&'))
            # --- ä¿®æ­£ç»“æŸ ---
            
            # ä¿®æ­£åæ ‡é˜²æ­¢è¶Šç•Œ
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w, x2), min(h, y2)
            
            # è£å‰ªå›¾ç‰‡ (è¿™é‡Œå®ç°äº†ä½ æƒ³è¦çš„ï¼šåªç”¨ Boxï¼Œä¸ç”¨é€è§†å˜æ¢)
            crop_img = image[y1:y2, x1:x2]
            
            # é˜²æ­¢ç©ºè£å‰ª
            if crop_img.shape[0] == 0 or crop_img.shape[1] == 0:
                raise ValueError("Empty crop")

            # 2. è§£æ Label - å¯¹åº”ç´¢å¼• 4
            # æ ¼å¼: 0_0_22_27_27_33_16 (Indexes in Provinces, Alphabets, Ads)
            lbl_indices = split_name[4].split('_')
            label_str = []
            
            # CCPD è§„åˆ™: 
            # ç¬¬1ä½: Province
            label_str.append(PROVINCES[int(lbl_indices[0])])
            # ç¬¬2ä½: Alphabet
            label_str.append(ALPHABETS[int(lbl_indices[1])])
            # ç¬¬3-7ä½: Ads (Alphabet + Digits)
            for i in range(2, 7):
                label_str.append(ADS[int(lbl_indices[i])])
            
            # å°†æ±‰å­—/å­—ç¬¦è½¬æ¢ä¸ºå…¨å±€ CHARS çš„ç´¢å¼•
            label = [CHAR_DICT[c] for c in label_str]
            label = np.array(label, dtype=np.int32)
            
            # 3. å›¾ç‰‡é¢„å¤„ç† (Resize -> Normalize -> Transpose)
            # LPRNet æ ‡å‡†è¾“å…¥æ˜¯ (94, 24)
            crop_img = cv2.resize(crop_img, self.img_size)
            # å½’ä¸€åŒ–åˆ° [-1, 1] æˆ–è€…æ˜¯ [0, 1]ï¼ŒLPRNet åŸç‰ˆä¹ æƒ¯å‡ 127.5
            crop_img = crop_img.astype('float32')
            crop_img -= 127.5
            crop_img *= 0.0078125
            crop_img = np.transpose(crop_img, (2, 0, 1)) # HWC -> CHW

            return torch.from_numpy(crop_img), torch.from_numpy(label), len(label)

        except Exception as e:
            # print(f"Error processing {filename}: {e}")
            # å‡ºé”™å°±æ¢ä¸€å¼ å›¾è¯»ï¼Œä¿è¯è®­ç»ƒä¸ä¸­æ–­
            return self.__getitem__(np.random.randint(self.__len__()))

print(f"âœ… å…¨å±€å­—ç¬¦è¡¨é•¿åº¦: {len(CHARS)}")
print(f"ç¤ºä¾‹å­—ç¬¦è¡¨: {CHARS[:10]} ...")

# ä¿®æ”¹è¿™é‡Œçš„ ROOT_PATH ä¸ºä½ å®é™…æŒ‚è½½çš„è·¯å¾„
# ä½ å¯ä»¥é€šè¿‡ ls å‘½ä»¤æŸ¥çœ‹ï¼š !ls /kaggle/input/
DATASET_ROOT = "/kaggle/input/ccpd-preprocess/CCPD2019"  # <--- è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è¿™é‡Œï¼ï¼
SPLIT_FOLDER = os.path.join(DATASET_ROOT, "splits")

def get_image_paths(txt_file):
    with open(txt_file, 'r') as f:
        lines = f.readlines()
    # æ‹¼æ¥å®Œæ•´è·¯å¾„
    return [os.path.join(DATASET_ROOT, line.strip()) for line in lines]

# è¯»å– all_train.txt å’Œ all_test.txt
train_txt = os.path.join(SPLIT_FOLDER, "all_train.txt")
test_txt = os.path.join(SPLIT_FOLDER, "all_test.txt")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœè·¯å¾„ä¸å¯¹ï¼Œè¯·æ‰‹åŠ¨è°ƒæ•´ DATASET_ROOT
if not os.path.exists(train_txt):
    print(f"âŒ æ‰¾ä¸åˆ° split æ–‡ä»¶: {train_txt}")
    print("è¯·ä½¿ç”¨ !find /kaggle/input -name 'all_train.txt' æŸ¥æ‰¾çœŸå®è·¯å¾„")
else:
    train_paths = get_image_paths(train_txt)
    test_paths = get_image_paths(test_txt)
    
    print(f"âœ… è®­ç»ƒé›†åŠ è½½: {len(train_paths)} å¼ ")
    print(f"âœ… æµ‹è¯•é›†åŠ è½½: {len(test_paths)} å¼ ")

    # æ„å»º DataLoader
    train_dataset = CCPDDataset(train_paths)
    val_dataset = CCPDDataset(test_paths)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)
    
sys.path.append('/kaggle/working/LPRNet_Pytorch')
from model.LPRNet import LPRNet

# ä¿®æ”¹ LPRNet åˆå§‹åŒ–ä»£ç 
# lpr_max_len=8: è½¦ç‰Œæœ€å¤§é•¿åº¦ï¼ˆCCPDæ˜¯7ä½ï¼Œä¸€èˆ¬è®¾ä¸º8é¢„ç•™ä¸€ä½æˆ–ä½œä¸ºæ ‡å‡†ï¼‰
# phase=True: è¡¨ç¤ºå½“å‰æ˜¯è®­ç»ƒé˜¶æ®µ (ä¼šå¯ç”¨ Dropout)
lprnet = LPRNet(lpr_max_len=8, phase=True, class_num=len(CHARS), dropout_rate=0.5)

lprnet = lprnet.cuda()

# ============================================================
# ğŸŸ¢ æ–°å¢/ä¿®æ”¹ä»£ç : åŠ è½½æ–­ç‚¹æƒé‡ (Resume Training)
# ============================================================
# è¿™é‡Œå¡«å†™ä½ æƒ³è¦åŠ è½½çš„æƒé‡æ–‡ä»¶è·¯å¾„
# å¦‚æœæ˜¯åŒä¸€ç¯å¢ƒæœªé‡å¯ï¼Œè·¯å¾„é€šå¸¸æ˜¯ '/kaggle/working/weights/lprnet_best.pth'
# å¦‚æœä½ é‡å¯äº†ç¯å¢ƒï¼Œä½ éœ€è¦ä¸Šä¼ ä¹‹å‰çš„æƒé‡å¹¶ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„
RESUME_WEIGHT_PATH = '/kaggle/input/lprnet/pytorch/default/1/lprnet_epoch_3.pth' 

if os.path.exists(RESUME_WEIGHT_PATH):
    print(f"ğŸ”„ å‘ç°é¢„è®­ç»ƒæƒé‡: {RESUME_WEIGHT_PATH}")
    # åŠ è½½æƒé‡
    lprnet.load_state_dict(torch.load(RESUME_WEIGHT_PATH))
    print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼å°†åœ¨è¯¥åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚")
    
    # ã€å¯é€‰ã€‘å¦‚æœä½ çŸ¥é“ä¹‹å‰çš„æœ€ä½³å‡†ç¡®ç‡ï¼ˆä¾‹å¦‚ 85%ï¼‰ï¼Œå¯ä»¥æ‰‹åŠ¨è®¾ç½®ï¼Œé˜²æ­¢åˆšå¼€å§‹è®­ç»ƒæ•ˆæœä¸å¥½æŠŠå¥½æ¨¡å‹è¦†ç›–äº†
    # best_acc = 0.85 
else:
    print("âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ (Start from scratch)ã€‚")
# ============================================================

print("âœ… LPRNet æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
print(lprnet)

# çœ‹çœ‹ STN æ˜¯å¦å¼€å¯ (LPRNet é»˜è®¤å¸¦ STN)
print(lprnet)

import os

# 1. æ ¹æ®ä½ çš„æˆªå›¾ï¼Œè¿™æ˜¯ç»å¯¹æ­£ç¡®çš„æ ¹ç›®å½•è·¯å¾„
DATASET_ROOT = "/kaggle/input/ccpd-preprocess/CCPD2019"

def get_image_paths(txt_file):
    valid_paths = []
    
    # æ£€æŸ¥ split æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(txt_file):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç´¢å¼•æ–‡ä»¶: {txt_file}")
        
    with open(txt_file, 'r') as f:
        lines = f.readlines()
        
    print(f"æ­£åœ¨å¤„ç† {os.path.basename(txt_file)}ï¼Œå…± {len(lines)} è¡Œ...")
    
    for line in lines:
        line = line.strip()
        if not line: continue
        
        # --- è·¯å¾„æ¸…æ´—é€»è¾‘ (å…³é”®æ­¥éª¤) ---
        # åŸå§‹è¡Œå¯èƒ½æ˜¯: /tmp/CCPD2019/ccpd_base/xxx.jpg
        # æˆ‘ä»¬åªéœ€è¦: ccpd_base/xxx.jpg
        
        if "CCPD2019/" in line:
            # è¿™é‡Œçš„ split ä¼šæŠŠè·¯å¾„åˆ‡æˆä¸¤åŠï¼Œæˆ‘ä»¬å–åé¢é‚£åŠ
            # ä¾‹å¦‚: ['', 'ccpd_base/xxx.jpg']
            rel_path = line.split("CCPD2019/")[-1]
        else:
            # å¦‚æœè·¯å¾„é‡Œå±…ç„¶æ²¡æœ‰ CCPD2019ï¼Œé‚£å°±å‡è®¾å®ƒå·²ç»æ˜¯ç›¸å¯¹è·¯å¾„äº†
            rel_path = line
            
        # å»æ‰å¼€å¤´å¯èƒ½å­˜åœ¨çš„æ–œæ ï¼Œé˜²æ­¢ os.path.join å¤±æ•ˆ
        if rel_path.startswith('/'):
            rel_path = rel_path[1:]
            
        # æ‹¼æ¥æˆ Kaggle çš„çœŸå®è·¯å¾„
        full_path = os.path.join(DATASET_ROOT, rel_path)
        valid_paths.append(full_path)

    # --- éªŒè¯é€»è¾‘ï¼šæ£€æŸ¥ç¬¬ä¸€å¼ å›¾èƒ½ä¸èƒ½æ‰¾åˆ° ---
    if valid_paths:
        first_img = valid_paths[0]
        if not os.path.exists(first_img):
            print(f"âŒ è·¯å¾„ä¿®æ­£å¤±è´¥ï¼è¯·æ£€æŸ¥ï¼")
            print(f"åŸå§‹æ–‡æœ¬: {lines[0].strip()}")
            print(f"ä¿®æ­£åè·¯å¾„: {first_img}")
            print(f"æœŸæœ›çš„æ ¹ç›®å½•: {DATASET_ROOT}")
            raise FileNotFoundError("æ— æ³•æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œè·¯å¾„æ‹¼æ¥æœ‰è¯¯ã€‚")
        else:
            print(f"âœ… è·¯å¾„ä¿®æ­£æˆåŠŸï¼")
            print(f"ç¤ºä¾‹: {first_img}")
            
    return valid_paths

# 2. é‡æ–°åŠ è½½è·¯å¾„ (æŒ‡å‘ splits æ–‡ä»¶å¤¹)
train_txt = os.path.join(DATASET_ROOT, "splits/all_train.txt")
test_txt = os.path.join(DATASET_ROOT, "splits/all_test.txt")

try:
    train_paths = get_image_paths(train_txt)
    test_paths = get_image_paths(test_txt)

    # 3. åªæœ‰è·¯å¾„åŠ è½½æˆåŠŸåï¼Œæ‰é‡å»º DataLoader
    # (ä½ éœ€è¦ç¡®ä¿ä¹‹å‰å®šä¹‰è¿‡ CCPDDataset ç±»)
    train_dataset = CCPDDataset(train_paths)
    val_dataset = CCPDDataset(test_paths)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)

    print("\nğŸ‰ æ•°æ®é›†åŠ è½½å®Œæ¯•ï¼Œç°åœ¨å¯ä»¥é‡æ–°è¿è¡Œè®­ç»ƒä»£ç å—äº†ï¼")

except Exception as e:
    print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
    
import torch
import torch.nn as nn
import torch.optim as optim
import os

# ================= é…ç½® =================
EPOCHS = 5
LEARNING_RATE = 0.001 
SAVE_DIR = '/kaggle/working/weights/'
best_acc = 0.0

# ç¡®ä¿æƒé‡ç›®å½•å­˜åœ¨
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

# 1. å®šä¹‰ Loss (CTCLoss)
# blank=len(CHARS)-1 è¡¨ç¤ºä½¿ç”¨æˆ‘ä»¬åœ¨ CHARS åˆ—è¡¨æœ€ååŠ çš„é‚£ä¸ª '-' ä½œä¸ºç©ºç™½ç¬¦
ctc_loss = nn.CTCLoss(blank=len(CHARS)-1, reduction='mean') 

# 2. å®šä¹‰ä¼˜åŒ–å™¨
optimizer = optim.Adam(lprnet.parameters(), lr=LEARNING_RATE)

# 2.5 å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½™å¼¦é€€ç«
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)

# 3. è§£ç å‡½æ•° (ç”¨äºè®¡ç®—å‡†ç¡®ç‡)
def greedy_decode(preds):
    preds = preds.argmax(dim=2)
    preds = preds.detach().cpu().numpy()
    res = []
    for i in range(preds.shape[1]): # batch size
        temp = []
        for k in range(preds.shape[0]): # time steps
            # å¦‚æœä¸æ˜¯ blank ä¸” (æ˜¯ç¬¬ä¸€ä¸ªå­—ç¬¦ OR ä¸å‰ä¸€ä¸ªå­—ç¬¦ä¸åŒ) -> ä¿å­˜
            if preds[k, i] != len(CHARS)-1 and (k==0 or preds[k, i] != preds[k-1, i]):
                temp.append(preds[k, i])
        res.append(temp)
    return res

# ================= è®­ç»ƒä¸»å¾ªç¯ =================
print(f"ğŸš€ å¼€å§‹è®­ç»ƒ... ç›®æ ‡è½®æ•°: {EPOCHS}")

for epoch in range(EPOCHS):
    lprnet.train()
    loss_val = 0
    
    # --- Training ---
    for i, (imgs, labels, lengths) in enumerate(train_loader):
        imgs = imgs.cuda()
        labels = labels.cuda() # è®­ç»ƒæ—¶ Label è¦ä¸Š GPU é…åˆæ¨¡å‹
        
        # LPRNet è¾“å‡ºçš„æ—¶é—´æ­¥é•¿å›ºå®šæ˜¯ 18 (é’ˆå¯¹ 94x24 çš„è¾“å…¥)
        input_lengths = (torch.ones(imgs.size(0)) * 18).int() 
        # CCPD è½¦ç‰Œå›ºå®šé•¿åº¦ 7
        target_lengths = torch.tensor([7] * imgs.size(0)).int() 
        
        # å°† batch çš„ label å±•å¹³ä»¥é€‚é… CTCLoss
        targets = []
        for label in labels:
            targets.extend(label.tolist())
        targets = torch.tensor(targets).int()
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        logits = lprnet(imgs)      # [batch, class_num, 18]
        logits = logits.permute(2, 0, 1) # [18, batch, class_num]
        logits = logits.log_softmax(2)
        
        # è®¡ç®— Loss
        loss = ctc_loss(logits, targets, input_lengths, target_lengths)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        loss_val += loss.item()
        
        if i % 50 == 0: # æ¯50ä¸ªbatchæ‰“å°ä¸€æ¬¡
            print(f"Epoch [{epoch+1}/{EPOCHS}] Iter [{i}/{len(train_loader)}] Loss: {loss.item():.4f}")

    # --- Validation ---
    lprnet.eval()
    correct = 0
    total = 0
    print(f"ğŸ” æ­£åœ¨éªŒè¯ç¬¬ {epoch+1} è½®æ¨¡å‹...")
    
    with torch.no_grad():
        for imgs, labels, _ in val_loader:
            imgs = imgs.cuda()
            # æ³¨æ„ï¼šè¿™é‡Œ labels ä¸éœ€è¦ .cuda()ï¼Œå› ä¸ºåé¢çš„å¯¹æ¯”é€»è¾‘æ˜¯åœ¨ CPU ä¸Šè¿›è¡Œçš„
            
            logits = lprnet(imgs)
            logits = logits.permute(2, 0, 1)
            
            # è§£ç 
            preds = greedy_decode(logits)
            
            # å¯¹æ¯”çœŸå€¼
            for j in range(len(preds)):
                pred_label = preds[j]
                # labels æ˜¯ DataLoader å‡ºæ¥çš„ CPU Tensor
                true_label = labels[j].numpy().tolist()
                
                if pred_label == true_label:
                    correct += 1
                total += 1
    
    acc = correct / total
    print(f"ğŸ† Epoch {epoch+1} éªŒè¯å‡†ç¡®ç‡: {acc*100:.2f}%")
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if acc > best_acc:
        best_acc = acc
        save_path = os.path.join(SAVE_DIR, f'lprnet_best.pth') # ä¿å­˜ä¸€ä¸ªå›ºå®šåå­—æ–¹ä¾¿ä¸‹è½½
        torch.save(lprnet.state_dict(), save_path)
        print(f"ğŸ”¥ æ–°çºªå½•ï¼æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {save_path}")
    
    # ä¹Ÿå¯ä»¥ä¿å­˜è¿™ä¸€è½®çš„ checkpoint (å¯é€‰)
    torch.save(lprnet.state_dict(), os.path.join(SAVE_DIR, 'lprnet_last.pth'))
    
    # ä¿å­˜æ¯ä¸€è½® (å¢é‡å¼ä¿å­˜ï¼Œç”¨äºå†å²å›æº¯) <--- è¿™é‡Œæ˜¯ä½ æƒ³è¦çš„
    epoch_path = os.path.join(SAVE_DIR, f'lprnet_epoch_{epoch+1}.pth')
    torch.save(lprnet.state_dict(), epoch_path)
    print(f"ğŸ“‚ å·²å½’æ¡£æœ¬è½®æƒé‡: {epoch_path}")
    
    # æ›´æ–°å­¦ä¹ ç‡ï¼ˆä½™å¼¦é€€ç«ï¼‰
    scheduler.step()
    print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")