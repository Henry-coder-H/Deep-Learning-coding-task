# 车牌识别

本目录包含基于 **CCPD2020** 数据集 (Test部分) 的车牌识别评估代码与检测代码。

1.  **evaluate1.py**：**端到端评估**。使用 PaddleOCR 同时完成“车牌位置检测” + “车牌字符识别”。
2.  **evaluate2.py**：**仅识别评估**。利用 CCPD2020 数据集提供的真值坐标 (Ground Truth) 裁剪车牌，仅测试识别模型的理论上限。
3.  **test.py** ：**通用检测**。支持视频/图片的稳定识别车牌。
> **鲁棒性指标说明：**  
> 原先鲁棒性，“大角度倾斜(>30°)”是通过车牌在图像平面内的旋转角来定义的。具体做法是：  
> 1. 从 CCPD 文件名中解析出车牌四个顶点 `pts4`（shape = (4, 2)），这四个点是车牌在原图上的四个角点；  
> 2. 将这四个点排成标准顺序 `tl, tr, br, bl`（分别表示左上、右上、右下、左下）；  
> 3. 用车牌上边向量 `tl -> tr` 的斜率计算平面内旋转角  
>    即代码中的 `theta = atan2(try - tly, trx - tlx)`（单位为弧度，后续再转换为角度）。
>
> 在 CCPD 的 test 集上统计发现：满足 `|θ| > 30°` 的图片只有 **9 张**，满足 `|θ| > 20°` 的也仅有 **47 张**，如果直接用“角度阈值”来定义鲁棒性子集，样本数量过少，评估结果不稳定。  
> 因此目前代码鲁棒性的定义改为基于**透视强度**的分位数划分：  
> - 先对每张图，从文件名解析出车牌四点 `vertices`；  
> - 用这四个点计算一个标量 `perspective_score`，表示车牌透视畸变的强度；  
> - 对所有样本的 `perspective_score` 取 0.90 分位数作为阈值（quantile = 0.90）；  
> - 将 `perspective_score` 大于等于该阈值的样本定义为“**强透视子集**”（即透视畸变最严重的那一批车牌），用来评估模型在强透视场景下的鲁棒性表现。
---

## 1. 环境配置 

实际实验环境如下：

- **OS**: Ubuntu 22.04
- **GPU**: NVIDIA RTX 4090
- **CUDA**: 12.4
- **Python**: 3.10 
- **深度学习框架及依赖**:
  - `paddlepaddle-gpu` (CUDA 11.8 版本，兼容性运行)
  - `paddleocr`
  - `ultralytics` (用于 YOLO识别车辆)

---

## 2. 实验输出与文件说明
- `err1/`  
  由 **evaluate1.py** 生成的错误样本可视化图片，主要错误类型包括：
  1. 未能正确检测到车牌；
  2. 车牌检测到位，但识别结果错误，例如：
     - 省份汉字识别错误；
     - 字符 `0` 与 `D` / `O` 混淆等。

- `err2/`  
  由 **evaluate2.py** 生成的错误样本可视化图片。  
  此时车牌位置使用 CCPD2020 的真值框，仅反映**识别模型本身**的错误情况。


- 评估结果 txt  
  - `final_report1.txt`：**evaluate1.py** 的整体评估结果（整牌准确率、字符级准确率、耗时等统计指标）；  
  - `final_report2.txt`：**evaluate2.py** 的整体评估结果。  

**演示脚本输出结果展示：**
![alt text](image.png)



---

## 3. 现状分析
### 3.1 评估阶段分析
1.  **检测环节的损耗**: `evaluate1` 与 `evaluate2` 的全字匹配率相差约 **4.7%**。查看可视化结果发现 PaddleOCR 的通用文本检测模型在定位车牌时存在一定的误差（例如：误将车身上的广告文字、标语识别为车牌，或者框选范围不精准无法识别车牌位置）。
2.  **识别能力的瓶颈**: 即便是在拥有完美定位（使用 GT 框）的 `evaluate2` 中，准确率上限也仅为 **91.96%**。这表明主要的性能瓶颈在于**识别模型**本身，而非检测模型。
3.  **数据集难点**: 经人工排查，CCPD2020 数据集中包含一些**模糊不清**的样本，部分图片即使是人眼也难以准确辨认。

### 3.2 检测阶段分析
**主要问题**：外国车牌识别正确率很高，但中文省份字符识别仍不够稳定；目前代码在检测阶段已经加入了多种针对车牌场景的约束与增强策略（车牌与车辆裁剪后的多倍上采样、基于正则与质量打分的候选过滤、可选的透视矫正、多帧缓存与结果升级机制、IoU 关联与置信度阈值控制等），尽量留存带中文的车牌，过滤远处或伪车牌框并稳定同一辆车在视频中的识别结果。


## 4. 待优化部分

1. **优化检测器（让 evaluate1 更接近 evaluate2）**
   - 问题：PaddleOCR 自带的是**通用文本检测器**，在车牌场景中容易受到车身文字、路牌、广告牌等背景文字的干扰，导致误检/漏检，从而拉低端到端准确率。
   - 方案：
     - 使用专门的目标检测模型（如 **YOLOv8 / YOLOv10** 等）单独训练“车牌检测器”，只检测车牌这一类目标；

     - 在检测阶段：增加对候选框的规则筛选，如长宽比范围、面积阈值、相对位置约束等，使 evaluate1 的输入更接近 evaluate2 中的“真值车牌框”

2. **微调识别模型**
   - 问题：在使用真值车牌框的前提下，整牌准确率的上限约为 **91.96%**，说明识别模型本身在遮挡、模糊等极端样本上仍存在瓶颈。
  
3. **基于规则的识别约束**
   - 评估代码中的错误大多集中在“车牌太模糊/太小导致检测不到或中文形近字识别错误”。如果只追求评估指标，可以通过手工维护形近字映射（例如将少数高频错误的形近字进行替换），在实验中曾尝试过，整牌正确率可提升约 1%。但由于这种方式依赖人工规则，带有一定“投机”成分，因此未纳入最终代码。
   - 也可以考虑从错误样本统计得到的混淆矩阵；再维护形近字映射列表。
   - 从实际应用的角度，思考通过**规则约束 + 模型改进**来提升性能：
      - 在送入识别模型前，引入轻量级的超分网络（如 SRGAN 或 ESPCN）或传统的图像处理算法（如 LapSRN），专门针对车牌区域进行 **4x 超分重建**，物理上增加汉字的像素特征，恢复边缘细节。
    
      - 针对光照不足导致的模糊，在裁剪车牌后应用 CLAHE限制对比度自适应直方图均衡化，增强汉字笔画与底色的对比度，使其更容易被卷积核激活。
  