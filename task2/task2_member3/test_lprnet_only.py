import sys
import os
import cv2
import torch
import numpy as np
import time

# ================= é…ç½®åŒºåŸŸ =================
# æ•°æ®é›†æ ¹ç›®å½•å’Œæµ‹è¯•é›†åˆ†å‰²æ–‡ä»¶
DATASET_ROOT = r"CCPD2019/CCPD2019"
TEST_SPLIT_FILE = r"CCPD2019/CCPD2019/splits/all_test.txt"

# LPRNetæƒé‡è·¯å¾„
# LPR_WEIGHTS = 'LPRNet_Pytorch/weights/Final_LPRNet_model.pth'
# LPR_WEIGHTS = 'weights/lprnet_epoch_3.pth'
LPR_WEIGHTS = 'weights/lprnet_best.pth'
# LPR_WEIGHTS = 'YOLOv5-LPRNet-Licence-Recognition/weights/lprnet_best.pth'

# éšæœºé‡‡æ ·å¼€å…³ï¼ˆTrue: éšæœºé€‰500å¼ ï¼ŒFalse: æµ‹è¯•å…¨éƒ¨ï¼‰
RANDOM_SAMPLE = True
SAMPLE_SIZE = 1000

# å¤§è§’åº¦ç­›é€‰å¼€å…³ï¼ˆTrue: åªæµ‹è¯•å¤§è§’åº¦å€¾æ–œ>30Â°ï¼ŒFalse: æµ‹è¯•æ‰€æœ‰ï¼‰
LARGE_TILT_ONLY = False
TILT_THRESHOLD = 30  # å¤§è§’åº¦é˜ˆå€¼ï¼ˆåº¦ï¼‰

# ================= å¼•å…¥ LPRNet =================
current_dir = os.path.dirname(os.path.abspath(__file__))
lprnet_path = os.path.join(current_dir, 'LPRNet_Pytorch')
if lprnet_path not in sys.path:
    sys.path.append(lprnet_path)
    
from model.LPRNet import LPRNet

# ================= CCPD æ•°æ®é›†è§£æ =================
CCPD_PROVINCES = ["çš–", "æ²ª", "æ´¥", "æ¸", "å†€", "æ™‹", "è’™", "è¾½", "å‰", "é»‘", "è‹", "æµ™", "äº¬", "é—½", "èµ£", "é²", "è±«", "é„‚", "æ¹˜", "ç²¤", "æ¡‚", "ç¼", "å·", "è´µ", "äº‘", "è—", "é™•", "ç”˜", "é’", "å®", "æ–°", "è­¦", "å­¦", "O"]
CCPD_ADS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']

# ================= LPRNet å­—ç¬¦è¡¨ =================
# CHARS = ['äº¬', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 
#          'è‹', 'æµ™', 'çš–', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 
#          'æ¡‚', 'ç¼', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', 'é’', 'å®', 
#          'æ–°', 
#          '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 
#          'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 
#          'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 
#          'W', 'X', 'Y', 'Z', 'I', 'O', '-'
# ]

# LPRNet è®­ç»ƒéœ€è¦çš„å…¨å±€å­—ç¬¦è¡¨ï¼ˆå»é‡å¹¶æ’åºï¼Œä¿æŒ 'O' ä½œä¸ºç©ºç™½ç¬¦åœ¨æœ€åæˆ–è€…æ˜¯ç‰¹å®šçš„ä½ç½®ï¼‰
# è¿™é‡Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯èƒ½å­—ç¬¦çš„åˆ—è¡¨
CHARS = ['çš–', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'è‹',
          'æµ™', 'äº¬', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼',
            'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', "é’", "å®", "æ–°", "è­¦", "å­¦", 
         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N',
           'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 
         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'] # æœ€ååŠ ä¸ª '-' ä½œä¸ºç©ºç™½ç¬¦(blank)

def parse_ccpd_filename(filename):
    """ä» CCPD æ–‡ä»¶åä¸­æå–è½¦ç‰Œå·å’Œå€¾æ–œè§’åº¦"""
    try:
        base_name = os.path.basename(filename)
        parts = base_name.split('-')

        # å€¾æ–œè§’åº¦
        tilt_info = parts[1].split('_')
        horizontal_tilt_raw = int(tilt_info[0])
        vertical_tilt_raw = int(tilt_info[1])

        # è§„åˆ™ï¼šä»¥ 'ccpd_base' å’Œ 'ccpd_green' å¼€å¤´çš„ç›¸å¯¹ 90Â° ä¸ºåŸºå‡†ï¼Œ
        # å…¶ä»–è·¯å¾„ä»¥ 0Â° ä¸ºåŸºå‡†ã€‚ä½¿ç”¨ä¼ å…¥çš„ç›¸å¯¹è·¯å¾„åˆ¤æ–­ç¬¬ä¸€æ®µç›®å½•åã€‚
        norm = filename.replace('\\', '/').lstrip('./')
        first_comp = norm.split('/')[0].lower() if norm else ''
        if first_comp in ('ccpd_base', 'ccpd_green'):
            baseline = 90
        else:
            baseline = 0

        horizontal_tilt = abs(horizontal_tilt_raw - baseline)
        vertical_tilt = abs(vertical_tilt_raw - baseline)
        max_tilt = max(horizontal_tilt, vertical_tilt)
        
        # è½¦ç‰Œå·
        label_str = parts[4] 
        idxs = label_str.split('_')
        province = CCPD_PROVINCES[int(idxs[0])]
        rest = [CCPD_ADS[int(i)] for i in idxs[1:]]
        plate_number = province + "".join(rest)
        
        return plate_number, max_tilt
    except Exception as e:
        return None, None

def parse_ccpd_bbox(filename):
    """ä» CCPD æ–‡ä»¶åä¸­æå–çœŸå€¼è¾¹ç•Œæ¡†åæ ‡"""
    try:
        base_name = os.path.basename(filename)
        parts = base_name.split('-')
        bbox_str = parts[2]
        
        # åˆ†å‰²ä¸¤ä¸ªç‚¹: x1&y1 å’Œ x2&y2
        points = bbox_str.split('_')
        pt1 = points[0].split('&')
        pt2 = points[1].split('&')
        
        x1, y1 = int(pt1[0]), int(pt1[1])
        x2, y2 = int(pt2[0]), int(pt2[1])
        
        return x1, y1, x2, y2
    except Exception as e:
        return None, None, None, None

def load_lprnet(weights_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    lprnet = LPRNet(lpr_max_len=8, phase=False, class_num=len(CHARS), dropout_rate=0)
    lprnet.to(device)
    lprnet.load_state_dict(torch.load(weights_path, map_location=device))
    lprnet.eval()
    return lprnet, device

def decode_lpr_output(preds):
    preds = preds.cpu().detach().numpy()
    label_indices = np.argmax(preds, axis=1)
    decoded_str = ""
    last_char = -1
    for idx in label_indices[0]:
        if idx != last_char and idx != len(CHARS) - 1:
            decoded_str += CHARS[idx]
        last_char = idx
    return decoded_str

def preprocessing_lpr(img, device):
    img = cv2.resize(img, (94, 24))
    img = img.astype('float32')
    img -= 127.5
    img *= 0.0078125
    img = np.transpose(img, (2, 0, 1))
    img = torch.from_numpy(img).unsqueeze(0).to(device)
    return img

def main():
    # --- åˆå§‹åŒ– ---
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æµ‹è¯•é›†åˆ†å‰²æ–‡ä»¶: {TEST_SPLIT_FILE}")
    
    if not os.path.exists(TEST_SPLIT_FILE):
        print("âŒ æµ‹è¯•é›†åˆ†å‰²æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return
    
    with open(TEST_SPLIT_FILE, 'r') as f:
        image_paths = [line.strip() for line in f.readlines() if line.strip()]
    
    print(f"ğŸ“Š æµ‹è¯•é›†åŒ…å« {len(image_paths)} å¼ å›¾ç‰‡")
    
    # éšæœºé‡‡æ ·é€»è¾‘
    if RANDOM_SAMPLE and len(image_paths) > SAMPLE_SIZE:
        import random
        random.seed(42)
        image_paths = random.sample(image_paths, SAMPLE_SIZE)
        print(f"ğŸ“Š éšæœºé‡‡æ · {SAMPLE_SIZE} å¼ è¿›è¡Œæµ‹è¯•...\n")
    else:
        print(f"ğŸ”¢ å¼€å§‹æ‰¹é‡æµ‹è¯•...\n")
    
    # å¤§è§’åº¦ç­›é€‰é€»è¾‘
    if LARGE_TILT_ONLY:
        filtered_paths = []
        for img_rel_path in image_paths:
            _, max_tilt = parse_ccpd_filename(img_rel_path)
            if max_tilt is not None and max_tilt > TILT_THRESHOLD:
                filtered_paths.append(img_rel_path)
        image_paths = filtered_paths
        print(f"ğŸ” ç­›é€‰å¤§è§’åº¦å€¾æ–œç…§ç‰‡: {len(image_paths)} å¼  (å€¾æ–œ>{TILT_THRESHOLD}Â°)\n")
    
    total_files = len(image_paths)

    # åŠ è½½æ¨¡å‹
    print(f"ğŸš€ æ­£åœ¨åŠ è½½ LPRNet æ¨¡å‹: {LPR_WEIGHTS}...")
    lpr_model, device = load_lprnet(LPR_WEIGHTS)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}\n")

    # --- ç»Ÿè®¡è®¡æ•°å™¨ ---
    count_full_match = 0      # æ•´ç‰Œå…¨å¯¹
    count_char_correct = 0    # å­—ç¬¦è®¤å¯¹çš„æ€»æ•°
    count_char_total = 0      # å­—ç¬¦æ€»æ•°
    count_bbox_fail = 0       # è¾¹ç•Œæ¡†è§£æå¤±è´¥
    count_crop_fail = 0       # è£å‰ªå¤±è´¥ï¼ˆè¾¹ç•Œæ¡†å¼‚å¸¸ï¼‰
    
    # å¤§è§’åº¦å€¾æ–œç»Ÿè®¡
    count_large_tilt = 0
    count_large_tilt_correct = 0
    
    time_start_total = time.time()
    inference_times = []

    print("=" * 60)
    print("å¼€å§‹æµ‹è¯• LPRNetï¼ˆä½¿ç”¨çœŸå€¼è¾¹ç•Œæ¡†è£å‰ªï¼‰")
    print("=" * 60)

    # --- å¼€å§‹å¾ªç¯ ---
    for i, img_rel_path in enumerate(image_paths):
        img_path = os.path.join(DATASET_ROOT, img_rel_path)
        
        # 1. è§£æçœŸå€¼è½¦ç‰Œå·å’Œå€¾æ–œè§’åº¦
        ground_truth, max_tilt = parse_ccpd_filename(img_rel_path)
        if not ground_truth:
            continue
        
        is_large_tilt = max_tilt > 30

        # 2. è§£æçœŸå€¼è¾¹ç•Œæ¡†
        x1, y1, x2, y2 = parse_ccpd_bbox(img_rel_path)
        if x1 is None:
            count_bbox_fail += 1
            continue
        
        # 3. è¯»å–å›¾ç‰‡
        img = cv2.imread(img_path)
        if img is None:
            continue

        # 4. ä½¿ç”¨çœŸå€¼è¾¹ç•Œæ¡†è£å‰ªè½¦ç‰Œ
        h, w = img.shape[:2]
        pad = 3
        crop_y1, crop_y2 = max(0, y1-pad), min(h, y2+pad)
        crop_x1, crop_x2 = max(0, x1-pad), min(w, x2+pad)
        
        plate_crop = img[crop_y1:crop_y2, crop_x1:crop_x2]
        
        if plate_crop.size == 0 or plate_crop.shape[0] < 5 or plate_crop.shape[1] < 5:
            count_crop_fail += 1
            continue

        # --- è®¡æ—¶å¼€å§‹ ---
        t0 = time.time()

        # 5. LPRNet è¯†åˆ«
        try:
            input_tensor = preprocessing_lpr(plate_crop, device)
            with torch.no_grad():
                preds = lpr_model(input_tensor)
                detected_text = decode_lpr_output(preds)
        except Exception as e:
            detected_text = None
        
        # --- è®¡æ—¶ç»“æŸ ---
        t_cost = (time.time() - t0) * 1000
        inference_times.append(t_cost)

        # 6. å¯¹æ¯”ç»Ÿè®¡
        is_correct = False
        if detected_text:
            # å…¨å­—åŒ¹é…
            if detected_text == ground_truth:
                count_full_match += 1
                is_correct = True
            
            # å­—ç¬¦çº§åŒ¹é…
            length = min(len(detected_text), len(ground_truth))
            for j in range(length):
                if detected_text[j] == ground_truth[j]:
                    count_char_correct += 1
        
        # å¤§è§’åº¦å€¾æ–œç»Ÿè®¡
        if is_large_tilt:
            count_large_tilt += 1
            if is_correct:
                count_large_tilt_correct += 1

        # ç´¯è®¡å­—ç¬¦æ€»æ•°
        count_char_total += len(ground_truth)

        # æ‰“å°è¿›åº¦
        if (i+1) % 50 == 0:
            print(f"ğŸš€ è¿›åº¦: {i+1}/{total_files} | è¯†åˆ«: {detected_text} | çœŸå€¼: {ground_truth} | {'âœ…' if is_correct else 'âŒ'}")

    # --- è®¡ç®—æœ€ç»ˆæŒ‡æ ‡ ---
    total_time_sec = time.time() - time_start_total
    avg_latency = np.mean(inference_times) if inference_times else 0
    fps = 1000 / avg_latency if avg_latency > 0 else 0
    
    valid_samples = total_files - count_bbox_fail - count_crop_fail
    acc_full = (count_full_match / valid_samples) * 100 if valid_samples > 0 else 0
    acc_char = (count_char_correct / count_char_total) * 100 if count_char_total > 0 else 0
    acc_large_tilt = (count_large_tilt_correct / count_large_tilt) * 100 if count_large_tilt > 0 else 0

    # --- è¾“å‡ºæŠ¥è¡¨ ---
    print("\n" + "="*60)
    print("ğŸ“Š LPRNet è¯†åˆ«æ€§èƒ½è¯„ä¼°æŠ¥å‘Šï¼ˆä½¿ç”¨çœŸå€¼è¾¹ç•Œæ¡†ï¼‰")
    print("="*60)
    print(f"ğŸ“‚ æµ‹è¯•é›†:      {TEST_SPLIT_FILE}")
    print(f"ğŸ”¢ æµ‹è¯•æ ·æœ¬:    {total_files} å¼ ")
    print(f"âœ… æœ‰æ•ˆæ ·æœ¬:    {valid_samples} å¼ ")
    if count_bbox_fail > 0:
        print(f"âš ï¸ è¾¹ç•Œæ¡†è§£æå¤±è´¥: {count_bbox_fail} å¼ ")
    if count_crop_fail > 0:
        print(f"âš ï¸ è£å‰ªå¤±è´¥:    {count_crop_fail} å¼ ")
    print(f"â±ï¸ æ€»è€—æ—¶:      {total_time_sec:.2f} ç§’")
    print("-" * 60)
    print("1ï¸âƒ£  å‡†ç¡®ç‡æŒ‡æ ‡ (Accuracy)")
    print(f"   - å…¨å­—åŒ¹é…ç‡ (Full Match):  {acc_full:.2f}%")
    print(f"   - å­—ç¬¦å‡†ç¡®ç‡ (Char Acc):    {acc_char:.2f}%")
    print("-" * 60)
    print("2ï¸âƒ£  é€Ÿåº¦æŒ‡æ ‡ (Latency)")
    print(f"   - å¹³å‡è€—æ—¶ (Latency):       {avg_latency:.2f} ms")
    print(f"   - å¸§ç‡ (FPS):               {fps:.2f} FPS")
    print("-" * 60)
    print("3ï¸âƒ£  é²æ£’æ€§æŒ‡æ ‡ (Robustness)")
    print(f"   - å¤§è§’åº¦å€¾æ–œæ ·æœ¬æ•°:         {count_large_tilt} å¼  (å€¾æ–œ>30Â°)")
    print(f"   - å¤§è§’åº¦å€¾æ–œè¯†åˆ«ç‡:         {acc_large_tilt:.2f}%")
    print("="*60)
    print("ğŸ’¡ è¯´æ˜ï¼šæœ¬æµ‹è¯•ä½¿ç”¨æ–‡ä»¶åä¸­çš„çœŸå€¼è¾¹ç•Œæ¡†è£å‰ªè½¦ç‰Œï¼Œ")
    print("   çº¯ç²¹è¯„ä¼° LPRNet è¯†åˆ«èƒ½åŠ›ï¼Œä¸å— YOLO æ£€æµ‹ç²¾åº¦å½±å“ã€‚")

if __name__ == "__main__":
    main()
