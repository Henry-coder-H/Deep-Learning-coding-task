import sys
import os
import cv2
import torch
import numpy as np
import time
from ultralytics import YOLO
import psutil

# ================= é…ç½®åŒºåŸŸ =================
DATASET_ROOT = r"CCPD2019/CCPD2019"
TEST_SPLIT_FILE = r"CCPD2019/CCPD2019/splits/all_test.txt"
HARDTEST_SPLIT_FILE = r"CCPD2019/CCPD2019/splits/all_hardtest.txt"

YOLO_WEIGHTS = 'weights/license_plate_detector.pt'
LPR_WEIGHTS = 'weights/lprnet_best.pth'

# éšæœºé‡‡æ ·å¼€å…³ï¼ˆTrue: éšæœºé€‰500å¼ ï¼ŒFalse: æµ‹è¯•å…¨éƒ¨ï¼‰
RANDOM_SAMPLE = False
SAMPLE_SIZE = 500

# å¼•å…¥ LPRNet
current_dir = os.path.dirname(os.path.abspath(__file__))
lprnet_path = os.path.join(current_dir, 'LPRNet_Pytorch')
if lprnet_path not in sys.path:
    sys.path.append(lprnet_path)
    
from model.LPRNet import LPRNet

# ================= CCPD æ•°æ®é›†è§£ææ ‡å‡† =================
CCPD_PROVINCES = ["çš–", "æ²ª", "æ´¥", "æ¸", "å†€", "æ™‹", "è’™", "è¾½", "å‰", "é»‘", "è‹", "æµ™", "äº¬", "é—½", "èµ£", "é²", "è±«", "é„‚", "æ¹˜", "ç²¤", "æ¡‚", "ç¼", "å·", "è´µ", "äº‘", "è—", "é™•", "ç”˜", "é’", "å®", "æ–°", "è­¦", "å­¦", "O"]
CCPD_ADS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']

# ================= LPRNet å­—ç¬¦è¡¨ =================
CHARS = ['çš–', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'è‹', 'æµ™', 'äº¬', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', "é’", "å®", "æ–°", "è­¦", "å­¦", 
         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 
         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-']

def parse_ccpd_filename(filename):
    """ä» CCPD æ–‡ä»¶åä¸­æå–æ­£ç¡®è½¦ç‰Œå· (Ground Truth)"""
    try:
        base_name = os.path.basename(filename)
        parts = base_name.split('-')
        
        # ç¬¬4éƒ¨åˆ†: è½¦ç‰Œç´¢å¼•
        label_str = parts[4] 
        idxs = label_str.split('_')
        
        # æ˜ å°„è½¬æ¢
        province = CCPD_PROVINCES[int(idxs[0])]
        rest = [CCPD_ADS[int(i)] for i in idxs[1:]]
        
        plate_number = province + "".join(rest)
        return plate_number
    except Exception as e:
        return None

def load_lprnet(weights_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    lprnet = LPRNet(lpr_max_len=8, phase=False, class_num=len(CHARS), dropout_rate=0)
    lprnet.to(device)
    lprnet.load_state_dict(torch.load(weights_path, map_location=device))
    lprnet.eval()
    return lprnet, device

def decode_lpr_output(preds):
    preds = preds.cpu().detach().numpy()
    label_indices = np.argmax(preds, axis=1)
    decoded_str = ""
    last_char = -1
    for idx in label_indices[0]:
        if idx != last_char and idx != len(CHARS) - 1:
            decoded_str += CHARS[idx]
        last_char = idx
    return decoded_str

def preprocessing_lpr(img, device):
    img = cv2.resize(img, (94, 24))
    img = img.astype('float32')
    img -= 127.5
    img *= 0.0078125
    img = np.transpose(img, (2, 0, 1))
    img = torch.from_numpy(img).unsqueeze(0).to(device)
    return img

def main():
    print("=" * 60)
    print("ğŸ“Š è½¦ç‰Œè¯†åˆ«æ¨¡å‹æ€§èƒ½è¯„ä¼°")
    print("=" * 60)
    
    # --- è¯»å–æµ‹è¯•é›†å’Œhard testé›† ---
    print(f"\nğŸ“‚ æ­£åœ¨è¯»å–æµ‹è¯•é›†: {TEST_SPLIT_FILE}")
    with open(TEST_SPLIT_FILE, 'r') as f:
        test_paths = [line.strip() for line in f.readlines() if line.strip()]
    
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–é²æ£’æ€§æµ‹è¯•é›†: {HARDTEST_SPLIT_FILE}")
    with open(HARDTEST_SPLIT_FILE, 'r') as f:
        hardtest_paths = set([line.strip() for line in f.readlines() if line.strip()])
    
    total_test_images = len(test_paths)
    print(f"âœ… æµ‹è¯•é›†åŠ è½½å®Œæˆ: {total_test_images} å¼ å›¾ç‰‡")
    print(f"âœ… é²æ£’æ€§å­é›†: {len(hardtest_paths)} å¼ å›¾ç‰‡\n")
    
    # --- éšæœºé‡‡æ ·é€»è¾‘ ---
    if RANDOM_SAMPLE and len(test_paths) > SAMPLE_SIZE:
        import random
        random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°
        test_paths = random.sample(test_paths, SAMPLE_SIZE)
        total_test_images = len(test_paths)
        print(f"ğŸ“Š éšæœºé‡‡æ · {SAMPLE_SIZE} å¼ è¿›è¡Œæµ‹è¯•...\n")

    # --- åŠ è½½æ¨¡å‹ ---
    print("ğŸ¤– æ­£åœ¨åŠ è½½æ¨¡å‹...")
    yolo_model = YOLO(YOLO_WEIGHTS)
    lpr_model, device = load_lprnet(LPR_WEIGHTS)
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {device})\n")

    # --- ç»Ÿè®¡è®¡æ•°å™¨ ---
    # å…¨å±€ç»Ÿè®¡
    count_full_match = 0          # æ•´ç‰Œå…¨å¯¹çš„æ•°é‡
    count_char_correct = 0        # å­—ç¬¦è®¤å¯¹çš„æ€»æ•°
    count_char_total = 0          # å­—ç¬¦æ€»æ•°
    inference_times = []          # æ¨ç†è€—æ—¶
    
    # é²æ£’æ€§ç»Ÿè®¡ï¼ˆall_hardtest å­é›†ï¼‰
    hardtest_count = 0                  # å‚ä¸ç»Ÿè®¡çš„hard testæ ·æœ¬æ•°
    hardtest_full_match = 0             # hard testå…¨å¯¹æ•°é‡

    # --- å¼€å§‹è¯„ä¼° ---
    print("ğŸš€ å¼€å§‹æ‰¹é‡è¯„ä¼°...\n")
    time_start = time.time()
    
    for i, img_rel_path in enumerate(test_paths):
        # åˆ¤æ–­æ˜¯å¦å±äºhardtestå­é›†
        is_hardtest = img_rel_path in hardtest_paths
        
        img_path = os.path.join(DATASET_ROOT, img_rel_path)
        
        # 1. è§£æçœŸå€¼
        ground_truth = parse_ccpd_filename(img_rel_path)
        if not ground_truth:
            continue
        
        # 2. è¯»å–å›¾ç‰‡
        img = cv2.imread(img_path)
        if img is None:
            continue

        # --- æ¨ç†è®¡æ—¶å¼€å§‹ ---
        t0 = time.time()

        # 3. YOLO æ£€æµ‹
        results = yolo_model(img, verbose=False)
        
        detected_text = None
        
        # å¯»æ‰¾è½¦ç‰Œ
        for result in results:
            if len(result.boxes) > 0:
                box = result.boxes[0]
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                
                # è£å‰ª
                h, w = img.shape[:2]
                pad = 3
                crop_y1, crop_y2 = max(0, y1-pad), min(h, y2+pad)
                crop_x1, crop_x2 = max(0, x1-pad), min(w, x2+pad)
                plate_crop = img[crop_y1:crop_y2, crop_x1:crop_x2]
                
                # LPRNet è¯†åˆ«
                input_tensor = preprocessing_lpr(plate_crop, device)
                with torch.no_grad():
                    preds = lpr_model(input_tensor)
                    detected_text = decode_lpr_output(preds)
                break
        
        # --- æ¨ç†è®¡æ—¶ç»“æŸ ---
        t_cost = (time.time() - t0) * 1000  # ms
        inference_times.append(t_cost)

        # 4. ç»Ÿè®¡ç»“æœ
        is_correct = False
        if detected_text:
            # å…¨å­—åŒ¹é…
            if detected_text == ground_truth:
                count_full_match += 1
                is_correct = True
            
            # å­—ç¬¦çº§åŒ¹é…
            length = min(len(detected_text), len(ground_truth))
            for j in range(length):
                if detected_text[j] == ground_truth[j]:
                    count_char_correct += 1
        
        # ç´¯è®¡å­—ç¬¦æ€»æ•°
        count_char_total += len(ground_truth)
        
        # é²æ£’æ€§ç»Ÿè®¡
        if is_hardtest:
            hardtest_count += 1
            if is_correct:
                hardtest_full_match += 1

        # æ‰“å°è¿›åº¦
        if (i + 1) % 100 == 0:
            print(f"   å¤„ç†è¿›åº¦: {i+1}/{total_test_images} ({(i+1)/total_test_images*100:.1f}%)")

    # --- è®¡ç®—æŒ‡æ ‡ ---
    total_time = time.time() - time_start
    avg_latency = np.mean(inference_times) if inference_times else 0
    fps = 1000 / avg_latency if avg_latency > 0 else 0
    
    # å‡†ç¡®ç‡
    full_match_acc = (count_full_match / total_test_images) * 100
    char_acc = (count_char_correct / count_char_total) * 100 if count_char_total > 0 else 0
    
    # é²æ£’æ€§
    hardtest_acc = (hardtest_full_match / hardtest_count) * 100 if hardtest_count > 0 else 0

    # --- è¾“å‡ºç»“æœ ---
    print("\n" + "=" * 60)
    print("è¯„ä¼°ç»“æœ")
    print("=" * 60)
    print(f"è¯„æµ‹å›¾ç‰‡æ•°é‡: {total_test_images}")
    print()
    print("1. å‡†ç¡®ç‡ (Accuracy)")
    print(f"   - å…¨å­—åŒ¹é…ç‡ï¼ˆæ•´ç‰Œå…¨å¯¹ï¼‰: {full_match_acc:.2f}%")
    print(f"   - å­—ç¬¦å‡†ç¡®ç‡ï¼ˆé€å­—ç¬¦å¹³å‡ï¼‰: {char_acc:.2f}%")
    print()
    print("2. æ¨ç†é€Ÿåº¦ (Latency)")
    print(f"   - å¹³å‡å•å¼ è€—æ—¶: {avg_latency:.2f} ms")
    print(f"   - FPSï¼ˆæ¯ç§’å¤„ç†å¼ æ•°ï¼‰: {fps:.2f}")
    print()
    print("3. é²æ£’æ€§ (Robustness)")
    print(f"   - all_hardtest å­é›†æ•´ç‰ŒåŒ¹é…ç‡: {hardtest_acc:.2f}%   (æ ·æœ¬æ•°={hardtest_count})")
    print("=" * 60)
    print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print("=" * 60)

if __name__ == "__main__":
    main()
