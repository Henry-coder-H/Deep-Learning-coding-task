import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
import torchvision.transforms.functional as F 
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, cohen_kappa_score, confusion_matrix, accuracy_score
import argparse

# ================= ğŸ”§ æ ¸å¿ƒé…ç½® =================
DATA_DIR = '/data2/zhuangyn/Deep-Learning-coding-task/task1/dataset/BIT_CLS_Dataset'
BATCH_SIZE = 32

# 1. ä¸¥æ ¼æ˜ å°„å…³ç³» (å¿…é¡»ä¸è®­ç»ƒä¸€è‡´)
TARGET_CLASS_TO_IDX = {
    'Bus': 0,
    'Microbus': 1,
    'Minivan': 2,
    'Sedan': 3,
    'SUV': 4,
    'Truck': 5
}
# 2. ç±»åˆ«åç§°åˆ—è¡¨ (ç”¨äºç»˜å›¾å’ŒæŠ¥å‘Š)
CLASS_NAMES = list(TARGET_CLASS_TO_IDX.keys())
# ===============================================

class SquarePad:
    def __init__(self, target_size=224):
        self.target_size = target_size

    def __call__(self, img):
        w, h = img.size
        scale = self.target_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        img = F.resize(img, (new_h, new_w), interpolation=F.InterpolationMode.BILINEAR)
        pad_w = self.target_size - new_w
        pad_h = self.target_size - new_h
        padding = (pad_w // 2, pad_h // 2, pad_w - pad_w // 2, pad_h - pad_h // 2)
        return F.pad(img, padding, fill=0)

def get_model(model_name, num_classes):
    if model_name == 'resnet50':
        model = models.resnet50(weights=None)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
    elif model_name == 'mobilenet':
        model = models.mobilenet_v3_small(weights=None)
        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)
    elif model_name == 'swin_t':
        model = models.swin_t(weights=None)
        model.head = nn.Linear(model.head.in_features, num_classes)
    elif model_name == 'convnext_t':
        model = models.convnext_tiny(weights=None)
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    return model

def evaluate(model_type):
    model_path = f'best_{model_type}.pth'
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ æ­£åœ¨å‡†å¤‡è¯„ä¼°: {model_type}")

    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {model_path}")
        return

    data_transforms = transforms.Compose([
        SquarePad(224), 
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # --- 1. æ•°æ®åŠ è½½ä¸å¼ºåˆ¶å¯¹é½ ---
    val_path = os.path.join(DATA_DIR, 'val')
    val_dataset = datasets.ImageFolder(val_path, data_transforms)
    
    # ç‰©ç†è¦†ç›–æ ‡ç­¾ç´¢å¼•
    val_dataset.class_to_idx = TARGET_CLASS_TO_IDX
    val_dataset.samples = val_dataset.make_dataset(
        val_path, # è¿™é‡Œä¿®æ­£äº†å˜é‡åï¼Œç¡®ä¿èƒ½æ‰¾åˆ°è·¯å¾„
        TARGET_CLASS_TO_IDX, 
        extensions=('.jpg', '.jpeg', '.png')
    )
    
    print(f"âœ… æ ‡ç­¾å·²å¼ºåˆ¶å¯¹é½: {val_dataset.class_to_idx}")
    
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    num_classes = len(CLASS_NAMES)
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ ä¸ºäº†å…¼å®¹ä½ åç»­çš„å¯è§†åŒ–ä»£ç ï¼Œè¿™é‡Œå®šä¹‰ä¸€ä¸‹å°å†™çš„ class_names ğŸ”¥ğŸ”¥ğŸ”¥
    class_names = CLASS_NAMES 

    # --- 2. æ¨¡å‹åŠ è½½ ---
    model = get_model(model_type, num_classes)
    try:
        state_dict = torch.load(model_path, map_location=device)
        new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return
    
    model.to(device)
    model.eval()

    # 5. æ¨ç†å¹¶æ”¶é›†æ‰€æœ‰ç»“æœ
    all_preds = []
    all_labels = []

    print("â³ æ­£åœ¨è¿›è¡Œå…¨é‡æ¨ç†...")
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    # 6. è®¡ç®—é«˜çº§æŒ‡æ ‡
    # (1) æ•´ä½“ Accuracy
    acc = accuracy_score(all_labels, all_preds)
    
    # (2) Cohen's Kappa
    kappa = cohen_kappa_score(all_labels, all_preds)
    
    # (3) è¯¦ç»†æŠ¥å‘Š (è¿™é‡Œå¼€å§‹ä½¿ç”¨ class_namesï¼Œä¸Šé¢å·²ç»å®šä¹‰å¥½äº†)
    report_dict = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)
    
    print("\n" + "="*30)
    print(f"ğŸ“Š è¯„ä¼°ç»“æœæŠ¥å‘Š ({model_type})")
    print("="*30)
    print(f"Overall Accuracy:  {acc:.4f}")
    print(f"Cohen's Kappa:     {kappa:.4f}")
    print("-" * 30)

    # 7. ç”Ÿæˆç±»ä¼¼è®ºæ–‡çš„è¡¨æ ¼ (DataFrame)
    data = []
    for cls in class_names:
        row = {
            'Class': cls,
            'Precision (æŸ¥å‡†ç‡)': report_dict[cls]['precision'],
            'Recall (æŸ¥å…¨ç‡)': report_dict[cls]['recall'],
            'F1-Score': report_dict[cls]['f1-score'],
            'Support (æ ·æœ¬æ•°)': report_dict[cls]['support']
        }
        data.append(row)
    
    df = pd.DataFrame(data)
    # è®¡ç®—å‡å€¼è¡Œ
    mean_row = {
        'Class': 'Macro Avg',
        'Precision (æŸ¥å‡†ç‡)': report_dict['macro avg']['precision'],
        'Recall (æŸ¥å…¨ç‡)': report_dict['macro avg']['recall'],
        'F1-Score': report_dict['macro avg']['f1-score'],
        'Support (æ ·æœ¬æ•°)': '-'
    }
    df = pd.concat([df, pd.DataFrame([mean_row])], ignore_index=True)
    
    print(df.round(4).to_string(index=False))
    
    # ä¿å­˜è¡¨æ ¼åˆ° CSV
    csv_filename = f'evaluation_metrics_{model_type}.csv'
    df.round(4).to_csv(csv_filename, index=False)
    print(f"\nâœ… è¯¦ç»†æŒ‡æ ‡å·²ä¿å­˜è‡³ {csv_filename}")

    # 8. ç”»æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'{model_type} Confusion Matrix (Acc: {acc:.2%}, Kappa: {kappa:.3f})')
    
    img_filename = f'confusion_matrix_{model_type}.png'
    plt.savefig(img_filename)
    print(f"âœ… æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜è‡³ {img_filename}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Evaluate trained models')
    parser.add_argument('--model', type=str, default='mobilenet', 
                        choices=['resnet50', 'mobilenet', 'swin_t', 'convnext_t'])
    args = parser.parse_args()
    
    evaluate(args.model)